<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/07/18/hello-world/"/>
    <url>/2021/07/18/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>春季实习冲刺计划：链表交换专题</title>
    <link href="/2021/01/10/%E9%93%BE%E8%A1%A8%E4%BA%A4%E6%8D%A2/"/>
    <url>/2021/01/10/%E9%93%BE%E8%A1%A8%E4%BA%A4%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h2 id="1-基础，一个单链表的交换"><a href="#1-基础，一个单链表的交换" class="headerlink" title="1. 基础，一个单链表的交换"></a>1. 基础，一个单链表的交换</h2><p>这里以<a href="https://leetcode-cn.com/problems/reverse-linked-list/" target="_blank" rel="noopener">Leetcode 206</a> 为例子. </p><blockquote><p>206.反转链表<br>反转一个单链表。</p><p>示例:</p><p>输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL<br>输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL<br>进阶:<br>你可以迭代或递归地反转链表。你能否用两种方法解决这道题？<br>版权由Leetcode所有，如有侵权，请联系删除</p></blockquote><p>也是一个很基础的模板</p><p>首先说第一种思想：直接使用迭代，然后用头插法的方式，再将所有的Node插入新链表中，因为头插法是反向插入的，因此会起到反转的效果</p><p>这种的思路也很简单</p><ol><li>创建一个None做链表头。</li><li>迭代当前链表，将当前链表的Node插入新链表。</li></ol><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseList</span><span class="hljs-params">(self, head: ListNode)</span> -&gt; ListNode:</span>        <span class="hljs-string">"""        迭代        """</span>        final_list = <span class="hljs-literal">None</span>        <span class="hljs-keyword">while</span> head:            temp = head.next            head.next = final_list            final_list = head            head = temp        <span class="hljs-keyword">return</span> final_list</code></pre><p>其中<code>final_list</code>是新链表的head位置，初始为NULL，然后使用一个<code>while</code>循环去迭代，当前的链表<code>head</code>，然后使用头插法一步一步的将Node插入。</p><p>递归：</p><p>递归的思路主要集中在：</p><ol><li><code>reverseList</code> 将<code>head.next</code>部分的链表反转，例如要反转的链表是<code>[1,2,3,4]</code>, 首先先将<code>[2,3,4]</code>进行反转为<code>[4, 3, 2]</code></li><li>将<code>head</code>放在最后，例如： 然后将<code>[1]</code>放在<code>[4, 3, 2]</code>的后面<code>[4,3,2,1]</code></li></ol><blockquote><p>note: 这个思路有一个问题：如何找到2能捕获2的指针从而完成操作<code>2-&gt;next = 1</code>，最简单的思路是直接去遍历，但是很浪费事件，这里可以直接采用递归体中，先对后面的进行反转，然后再拼接前半部分的顺序，此时<code>[1]</code>的next其实依旧指向<code>[2]</code>，因此我们可以直接这样捕获，避免重新去查找。</p></blockquote><p>形成代码</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseList</span><span class="hljs-params">(self, head: ListNode)</span> -&gt; ListNode:</span>        <span class="hljs-keyword">if</span> head == <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> head.next == <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 防止出现None指针操作</span>            <span class="hljs-keyword">return</span> head        p = self.reverseList(head.next)        head.next.next = head        head.next = <span class="hljs-literal">None</span>        <span class="hljs-keyword">return</span> p</code></pre><h2 id="2-进一步提升，如果要两两替换呢？"><a href="#2-进一步提升，如果要两两替换呢？" class="headerlink" title="2. 进一步提升，如果要两两替换呢？"></a>2. 进一步提升，如果要两两替换呢？</h2><p>这里使用<a href="https://leetcode-cn.com/problems/swap-nodes-in-pairs/" target="_blank" rel="noopener">Leetcode 24</a>来说明这个问题。</p><blockquote><p>24.两两交换链表中的节点<br>给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。</p><p>你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。<br><img src="//luyanfcp.github.io/2021/01/10/链表交换/swap_ex1.jpg" srcset="/img/loading.gif" alt></p><p>输入：head = [1,2,3,4]<br>输出：[2,1,4,3]<br>示例 2：</p><p>输入：head = []<br>输出：[]<br>示例 3：</p><p>输入：head = [1]<br>输出：[1]</p><p>提示：</p><p>链表中节点的数目在范围 [0, 100] 内<br>0 &lt;= Node.val &lt;= 100</p><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode-cn.com/problems/swap-nodes-in-pairs" target="_blank" rel="noopener">https://leetcode-cn.com/problems/swap-nodes-in-pairs</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p></blockquote><p>这个依旧分为两个思路：迭代和递归</p><p>迭代：向后移动两个指针然后交换</p><p>迭代这里给两个版本</p><ol><li><p>需要使用指针的指针进行操作，因为需要获取到两个节点中前一个节点中的前一个节点的指针，在<code>python</code>中一般使用一个临时节点来充当指针的指针例如很多题解中的<code>dummy = ListNode(-1)</code>，另一方面也是增加一个头节点方便操作。如果是<code>C/C++</code>即可直接使用<code>**ListNode</code></p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">swapPairs</span><span class="hljs-params">(self, head: ListNode)</span> -&gt; ListNode:</span>        head_pointer = ListNode(<span class="hljs-number">-1</span>) <span class="hljs-comment"># 指针的指针，头节点</span>        pre = head_pointer         pre.next = head        first, second = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>  <span class="hljs-comment"># 两个节点中的第一个节点和第二个节点</span>        <span class="hljs-keyword">while</span> head <span class="hljs-keyword">and</span> head.next:   <span class="hljs-comment"># next 为 null即可退出</span>            first = head            second = head.next            pre.next = second       <span class="hljs-comment">#交换两节点</span>            first.next = second.next            second.next = first            pre = first             <span class="hljs-comment">#继续遍历后续节点</span>            head = first.next        <span class="hljs-keyword">return</span> head_pointer.next</code></pre></li><li><p>直接进行值交换</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">swapPairs</span><span class="hljs-params">(self, head: ListNode)</span> -&gt; ListNode:</span>        <span class="hljs-keyword">if</span> head == <span class="hljs-literal">None</span>:            <span class="hljs-keyword">return</span> head                first, second = head, head.next        <span class="hljs-keyword">while</span> second != <span class="hljs-literal">None</span>:            first.val, second.val = second.val, first.val            first = second.next            <span class="hljs-keyword">if</span> first == <span class="hljs-literal">None</span>:                <span class="hljs-keyword">break</span>            second = first.next                <span class="hljs-keyword">return</span> head</code></pre></li></ol><p>递归：向前移动两个指针，先将后半部分交换，再将当前位置交换，然后拼接.</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">swapPairs</span><span class="hljs-params">(self, head: ListNode)</span> -&gt; ListNode:</span>        <span class="hljs-keyword">if</span> head == <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> head.next == <span class="hljs-literal">None</span>:            <span class="hljs-keyword">return</span> head        next_node = head.next        head.next = self.swapPairs(next_node.next)        next_node.next = head        <span class="hljs-keyword">return</span> next_node</code></pre><h2 id="3-任意顺序的K个节点交换"><a href="#3-任意顺序的K个节点交换" class="headerlink" title="3. 任意顺序的K个节点交换"></a>3. 任意顺序的K个节点交换</h2><p>这里使用，<a href="https://leetcode-cn.com/problems/reverse-nodes-in-k-group/" target="_blank" rel="noopener">Leetcode25 K个一组翻转链表</a>作为例子。</p><p>由于K个交换过于复杂，这里没有采用迭代的思路，因为迭代的思路需要使用栈存储便利后的一些节点。使用递归思路和代码都比较简答。</p><p>首先将问题分为两个部分：</p><ol><li>K个节点如何交换。这个其实可以转化为问题1，直接套用问题一的模板即可。</li><li>判断k个节点的范围。</li></ol><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">swap</span><span class="hljs-params">(head: ListNode)</span>:</span>        final_list = <span class="hljs-literal">None</span>        <span class="hljs-keyword">while</span> head:            temp = head.next            head.next = final_list            final_list = head            head = temp        <span class="hljs-keyword">return</span> final_list <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseKGroup</span><span class="hljs-params">(self, head: ListNode, k: int)</span> -&gt; ListNode:</span>        <span class="hljs-keyword">if</span> k == <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> head == <span class="hljs-literal">None</span>:            <span class="hljs-keyword">return</span> head        end = head        <span class="hljs-comment"># 向后找k个节点</span>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(k<span class="hljs-number">-1</span>):            end = end.next  <span class="hljs-comment"># 向后的</span>            <span class="hljs-keyword">if</span> end == <span class="hljs-literal">None</span>:                <span class="hljs-keyword">return</span> head        end_next = end.next        <span class="hljs-comment"># end之后置空，方便swap函数进行判断</span>        end.next = <span class="hljs-literal">None</span>        <span class="hljs-comment"># 交换一下</span>        swap(head)        <span class="hljs-comment"># 拼起来</span>        head.next = self.reverseKGroup(end_next, k)</code></pre><p>时间复杂度为<code>O(n)</code>刚好扫描过所有的链表。空间复杂度由于是递归的问题存在一定的递归栈空间复杂度是<code>O(n/k)</code></p>]]></content>
    
    
    
    <tags>
      
      <tag>Leetcode</tag>
      
      <tag>数据结构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AIOPS笔记：GNN在异常检测上的应用论文（一）</title>
    <link href="/2020/11/21/2020-11-21-AIOPS%E7%AC%94%E8%AE%B0%EF%BC%9AGNN%E5%9C%A8%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8%E8%AE%BA%E6%96%87%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/2020/11/21/2020-11-21-AIOPS%E7%AC%94%E8%AE%B0%EF%BC%9AGNN%E5%9C%A8%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8%E8%AE%BA%E6%96%87%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h2 id="《A-Spatiotemporal-Deep-Learning-Approach-for-Unsupervised-Anomaly-Detection-in-Cloud-Systems》-笔记"><a href="#《A-Spatiotemporal-Deep-Learning-Approach-for-Unsupervised-Anomaly-Detection-in-Cloud-Systems》-笔记" class="headerlink" title="《A Spatiotemporal Deep Learning Approach for Unsupervised Anomaly Detection in Cloud Systems》 笔记"></a>《A Spatiotemporal Deep Learning Approach for Unsupervised Anomaly Detection in Cloud Systems》 笔记</h2><p>论文地址：<a href="https://ieeexplore.ieee.org/document/9228885/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/9228885/</a></p><p>论文数据集：<a href="https://github.com/QAZASDEDC/TopoMAD" target="_blank" rel="noopener">https://github.com/QAZASDEDC/TopoMAD</a></p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul><li><p>解决的问题场景：大规模云系统的中的异常检测问题。</p></li><li><p>引入GNN的角度：</p><ul><li>考虑单一的Metirc可以提供单个层面级别的信息，而考虑组件的多种Metric可以提供组件级别的信息。</li><li><strong>各组成部分的相互作用关系。</strong></li><li><strong>拓扑信息的输入和组件级的输入构成了系统级的信息，可以更全面地了解整个运行系统。</strong></li></ul></li><li>传统DNN方法的弊端：<ol><li>在决定组件是否处于异常状态时，有时需要考虑其连接的组件（一般DNN做不到）。</li><li>随着云系统复杂性的增加，为每个组件训练和维护单个模型的难度将越来越大。（尤其在微服务场景中，指标的数量成指数级增长，及其难维护）。</li><li>粗略地将整个系统看作一个笨重的组件会失去对其内部拓扑结构的洞察，从而可能增加对其正常行为建模的难度。</li></ol></li></ul><h3 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h3><ol><li><p>增加拓扑信息的好处：</p><ul><li><p>图神经网络的特征提取器共享于来自不同组件的同类指标之间，有助于在统一的特征学习下捕获相同指标类型之间的相似模式。</p></li><li><p>端到端的引入拓扑的影响。</p></li><li>拓扑信息可以引导模型将注意力集中在现实中具有直接连接和交互的组件上，这有助于防止模型的过拟合（GAT）。</li></ul></li><li><p>引入了无监督选择检测阈值的方法：</p><ul><li>过去的方法，类似DAGMM等，需要大量的阈值调参。在这里本论文引入无监督的模型来生成阈值，从而减少模型的调参难度。</li></ul></li></ol><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/1.png" srcset="/img/loading.gif" alt="image-20201120223734359"></p><p>总体设计如上图</p><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/2.png" srcset="/img/loading.gif" alt="image-20201120223940091"></p><p>数据分为两类：</p><ol><li>$X$ 为指标矩阵，横坐标是节点（Node），纵坐标是指标（Metric）。</li><li>$E$ 为连接矩阵，主要是<code>edge</code>的向量矩阵，每个<code>edge</code>为$E$的一个列向量。</li></ol><h3 id="模型设计"><a href="#模型设计" class="headerlink" title="模型设计"></a>模型设计</h3><p>模型在VAE和seq2seq的基础上进行设计：</p><ul><li>VAE因为其生成模型的特点，常作为异常检测的方法（生成模型能估计联合概率密度）。</li><li>Seq2Seq结构出自NLP领域，常用于序列建模，这也跟我们要处理的时间序列不谋而合。</li><li>在这两个模型的基础上，引入Graph 网络对拓扑信息进行学习。</li></ul><h4 id="1-GraphLSTM"><a href="#1-GraphLSTM" class="headerlink" title="1. GraphLSTM"></a>1. GraphLSTM</h4><p>GraphLSTM的主要思路是将LSTM中的全连接网络之前增加一个GNN，对拓扑信息和指标信息进行融合。</p><p>下面是两种LSTM的比较</p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/Graph_LSTM.png" srcset="/img/loading.gif" alt="GraphLSTM"></p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/traditional_LSTM.png" srcset="/img/loading.gif" alt="原有的LSTM"></p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/Graph_LSTM_function.png" srcset="/img/loading.gif" alt="公式"></p><p>红框部分是由标准的LSTM中的$[h<em>{t-1}, x_t]$替换为$g([h</em>{t-1},x_t], E)$, 也就在之前添加了GNN作为拓扑信息和Metric信息的融合层，融合之后作为标准LSTM的输入。</p><h4 id="2-TopoMAD"><a href="#2-TopoMAD" class="headerlink" title="2. TopoMAD"></a>2. TopoMAD</h4><p>之后论文提出了由<code>GraphLSTM</code>单元组成的<code>Seq2Seq+VAE</code> 的模型。在训练和推理阶段的结构如下图：</p><p>训练阶段：</p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/training.png" srcset="/img/loading.gif" alt="TopoMAD training stage"></p><p>推理阶段：</p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/inference.png" srcset="/img/loading.gif" alt="TopoMAD inference stage"></p><p>训练的时候<code>decoder</code>有$\lambda$的可能用原始输入$X$、$1-\lambda$使用重构后的值$X’$。（scheduled sampling process）</p><ul><li>初始化的时候$\lambda$=1之后当val loss不减少的时候, $\lambda$减半。</li></ul><p><strong>Loss</strong> 采用VAE的ELBO Loss结构：</p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/ELBO-loss.png" srcset="/img/loading.gif" alt="ELBO Loss"></p><h4 id="3-计算异常得分"><a href="#3-计算异常得分" class="headerlink" title="3. 计算异常得分"></a>3. 计算异常得分</h4><script type="math/tex; mode=display">\operatorname{temp} S_{t}=-\mathbf{E}_{q_{\phi}\left(z_{t} \mid X_{t_{0}: t}\right)}\left(\log \left(p_{\theta}\left(X_{t} \mid z_{t}\right)\right)\right)</script><script type="math/tex; mode=display">S_{t}=-\frac{1}{L * D} \sum_{d=0}^{D-1} \sum_{l=1}^{L} \log \left(p_{\theta}\left(X_{t} \mid z_{t+d}^{(l)}, X_{t+1: t+d}\right)\right)</script><p>使用重构误差做为异常得分的计算：这种思想源于<em>《Variational Autoencoder based Anomaly Detection using Reconstruction Probability》</em>。其中$L$是采样数量，$D$是计算或更新一个异常分数的次数(the tolerance of detection delay)。</p><p>但是在某些情况下，<strong>在某些情况下，系统中某个特定组件的相对较低的重构概率就足让我们将其判断为异常</strong>。 因此，我们还从组件角度计算异常分数，如下所示：</p><script type="math/tex; mode=display">S_{t}=-\max _{0 \leq i<N} \frac{1}{L * D} \sum_{d=0}^{D-1} \sum_{l=1}^{L} \log \left(p_{\theta}\left(X_{t}^{i} \mid z_{t+d}^{(l)}, X_{t+1: t+d}\right)\right)</script><p>也就是组件级别的异常。</p><h4 id="4-阈值的选择："><a href="#4-阈值的选择：" class="headerlink" title="4. 阈值的选择："></a>4. 阈值的选择：</h4><p>本文提出的阈值选择一种阈值选择方法，假设正常数据的异常分数位于密度较高的区域，异常数据的异常分数位于密度较低的区域。</p><script type="math/tex; mode=display">d\left(S_{<\tau}, S_{>\tau}\right)=\frac{\min \left(S_{>\tau}\right)-\max \left(S_{<\tau}\right)}{\min \left(S_{>\tau}\right)+\max \left(S_{<\tau}\right)-2 * \min \left(S_{<\tau}\right)}</script><p>基于这一假设，选择一个阈值，使该阈值从训练数据集中切割出的两个集合与一个算子提供的范围之间的距离最大化。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="总体上跟其他方法的对比"><a href="#总体上跟其他方法的对比" class="headerlink" title="总体上跟其他方法的对比"></a>总体上跟其他方法的对比</h4><p>本文实验使用了两个数据集，MBD（一个批处理的数据集）、NMS（微服务场景的数据集）。TopoMAD均好于传统方法。</p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/exp1.png" srcset="/img/loading.gif" alt="Comparative Experiment 1"></p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/exp2.png" srcset="/img/loading.gif" alt="Comparative Experiment 2"></p><h4 id="鲁棒性"><a href="#鲁棒性" class="headerlink" title="鲁棒性"></a>鲁棒性</h4><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/robustness_exp.png" srcset="/img/loading.gif" alt="Robustness Experiment"></p><h4 id="可解释性"><a href="#可解释性" class="headerlink" title="可解释性"></a>可解释性</h4><p>异常的隐变量和真实的隐变量差距不大，因此VAE不会重构异常。</p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/Interpretability_exp.png" srcset="/img/loading.gif" alt="Interpretability Experiment"></p><h4 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h4><p><strong>空间信息的作用</strong>：</p><p>实验方法是将$E$矩阵随机化，这样会混淆空间信息。结果表示在混淆空间信息之后，点数会有下降。</p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/Ablation_exp.png" srcset="/img/loading.gif" alt="Ablation Experiment Result1"></p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/Ablation_exp2.png" srcset="/img/loading.gif" alt="Ablation Experiment Result2"></p><h4 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/complexity.png" srcset="/img/loading.gif" alt="complexity"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本论文主要的目标是将拓扑信息融入到系统检测的过程中</p><ul><li>在传统的LSTM中使用GNN的方法引入了拓扑的信息。</li><li>VAE+Seq2Seq的形式，增加模型的学习能力。</li></ul><p>本文还有另外的一个特点就是论文的写作风格特别好（在实验部分使用QA的方式来阐述实验的各个部分），实验做的非常非常全。</p><p><img src="//luyanfcp.github.io/2020/11/21/2020-11-21-AIOPS笔记：GNN在异常检测上的应用论文（一）/questions.png" srcset="/img/loading.gif" alt="paper"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>论文</tag>
      
      <tag>笔记</tag>
      
      <tag>深度学习</tag>
      
      <tag>GNN</tag>
      
      <tag>异常检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git笔记</title>
    <link href="/2020/10/11/git%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/10/11/git%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><h2 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a>基础操作</h2><ol><li>初始化仓库<code>git init</code></li><li><code>git add [file]</code>， 将文件的修改部分增加如暂存区，修改了什么可以使用<code>git diff --cached</code>进行查看</li><li><code>git reset [file]</code>， 从暂存区</li><li><code>git commit -m &quot;commit信息&quot;</code> 将修改好的代码<code>commit</code>到仓库。</li><li><code>git push origin</code> 推送到<code>origin</code></li><li><code>git pull origin</code> 从远程服务器上拉取</li></ol><p><img src="//luyanfcp.github.io/2020/10/11/git笔记/1.png" srcset="/img/loading.gif" alt="Git基本结构"></p><h2 id="分支操作"><a href="#分支操作" class="headerlink" title="分支操作"></a>分支操作</h2><ol><li><p>查看分支<code>git branch</code>：查看分支所有<code>-a</code></p><p><img src="//luyanfcp.github.io/2020/10/11/git笔记/2.png" srcset="/img/loading.gif" alt="查看分支"></p></li><li><p>创建分支<code>git branch [branch_name]</code>：从当前分支创建新的分支。</p></li><li><p>修改分支名称<code>git branch -m [old_branch] [new_branch]</code>：重命名指定branch</p></li><li><p>删除<code>git branch -d [branch_name]</code>：</p></li><li><p>切换分支<code>git checkout [branch_name]</code>：</p></li><li><p>合并分支<code>git merge [branch_name]</code>和<code>git rebase [branch_name]</code>： 将<code>branch_name</code>合并到当前分支。</p></li></ol><h3 id="对分支回退的控制"><a href="#对分支回退的控制" class="headerlink" title="对分支回退的控制"></a>对分支回退的控制</h3><ol><li><p><code>reset</code>：只更改HEAD指针指向的commit id，如果这个操作撤回某些commit，则这些commit在log里会消失，<strong>并且这些commit引用会在git的垃圾回收处理过程中被删除</strong>，也就是这部分树枝之后会被锯掉。<code>git reset --hard (--soft, --fix) {[局部索引值]、[HEAD^](后退一部)、[HEAD~n](后退n步)}</code></p><ul><li><code>--soft</code>是仅仅在本地库中移动<code>HEAD</code>指针。</li><li><code>--mixed</code>是在本地库中移动指针，重置缓冲区。</li><li><code>--hard</code>是本地库、暂存区、工作区全部重置。</li></ul></li><li><p><code>checkout</code>：则为移动的目标指针单独建立一个分支，并移动HEAD，原分支不变。</p></li><li><p><code>revert</code>：新建一个commit，指针后移，并将目标commit的内容作为本次commit的内容，个人感觉这种操作更安全，毕竟会保留之前的记录。(但是要注意，如果你合并了某个分支，并且revert该分支中的一个commit，<strong>不要以为再合并一次这个分支就可以还原那个revert，是不行的，git会默认把这个revert导致的差异对冲掉，你如果想还原，要么reset或者revert那次revert</strong>， revert无法撤销分支的<code>merge</code>）。</p></li></ol><p><img src="//luyanfcp.github.io/2020/10/11/git笔记/3.png" srcset="/img/loading.gif" alt="revert log"></p><h4 id="指针的控制"><a href="#指针的控制" class="headerlink" title="指针的控制"></a>指针的控制</h4><p><code>^\~</code>前面为相对谁, 比如说相对master 或者相对</p><p><code>^</code> 第n个父亲， 如果有分支</p><p><code>~</code>第n个直系上级</p><p><img src="//luyanfcp.github.io/2020/10/11/git笔记/4.png" srcset="/img/loading.gif" alt="Git的指针的位置"></p><h3 id="merge和rebase的区别"><a href="#merge和rebase的区别" class="headerlink" title="merge和rebase的区别"></a>merge和rebase的区别</h3><p><code>merge</code>和<code>rebase</code>是两种合并分支的方式，其中<code>merge</code>是直接将两个分支有依赖的合并，<code>abcde</code>的节点需要依赖<code>Feature</code>分支。不同的是<code>rebase</code>合并，就是将<code>Feature</code>中做修改的部分直接合并进去<code>Master</code>作为一个单独的节点，不依赖<code>Feature</code>分支。不同的方式见图。</p><p><img src="//luyanfcp.github.io/2020/10/11/git笔记/5.png" srcset="/img/loading.gif" alt="Merge"></p><p><img src="//luyanfcp.github.io/2020/10/11/git笔记/6.png" srcset="/img/loading.gif" alt="rebase"></p><h2 id="远程操作"><a href="#远程操作" class="headerlink" title="远程操作"></a>远程操作</h2><ol><li><p>远程获取仓库：<code>git clone -o [remote主机名]</code> 可以增加<code>remote</code>主机名，默认为<code>origin</code></p></li><li><p>修改<code>remote</code>信息：<code>git remote</code>、<code>git remote show [主机名]</code>可以展示主机的详细信息。<code>git remote add/rm/rename [主机] [网址]</code> 可以添加、删除或者改名远程主机</p></li><li><p>获取远程服务器的修改信息：<code>git fetch</code>：从某个远程服务器中取回分支<code>git fetch [远程服务器] [分支名称]</code>，如果分支名称没指定的话就默认取回所有的分支。取回的分支名字在本地为<code>[主机名]/分支名</code>，例如<code>origin/master</code>，可以使用<code>git branch -r</code>的方式查看远程分支。</p></li><li><p>远程服务器与本地服务器合并<code>git pull</code>：<code>git pull [远程主机名] [远程分支名]:[本地分支名]</code>如果省略本地分支<code>[远程分支名]:[本地分支名]</code>的名称的话，就是合并到当前分支。如果省略远程主机名的话，回自动的合并当前分支绑定的远程分支。</p><ul><li><p><code>git pull origin master</code>  就等价于<code>git fetch origin &amp;&amp; git merge origin/master</code></p></li><li><p>在某些场合，Git会自动在本地分支与远程分支之间，建立一种追踪关系（tracking）。比如，在<code>git clone</code>的时候，所有本地分支默认与远程主机的同名分支，建立追踪关系，也就是说，本地的<code>master</code>分支自动”追踪”<code>origin/master</code>分支。如果要手动设置tracing关系<code>git branch --set-upstream [本地] [远程主机]/[分支名称]</code> </p></li><li><p>同样也可以使用<code>rebase</code>合并分支，只需要<code>--rebase</code></p></li><li><p><code>git pull</code> 不会拉取远程被删除的分支，防止本地的某些分支在不知情的情况下被删除。如果做响应的操作的话<code>--prune/-p</code></p></li></ul></li><li><p>向远程服务器推送信息<code>git push</code>：标准写法<code>git push [远程主机] [本地分支名]:[远程分支名]</code>。</p><ul><li><p>通<code>pull</code>如果不指定远程分支名称，则<code>push</code>到对应的trace分支，如果存在多个绑定的远程分支也可以使用<code>git push -u</code>指定一个默认的远程仓库，之后<code>git push</code>会自动的推送到该默认仓库。</p></li><li><p>如果其不存在会新建一个远程的分支。</p></li><li><p>如果<strong>省略本地分支名</strong>，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。</p><pre><code class="hljs shell">git push origin :xxx<span class="hljs-meta">#</span> 等价于git push origin --delete xxx</code></pre></li><li><p>如果需要推送所有分支<code>--all</code></p></li><li>如果本地比远程版本较老的话<code>push</code>会出错，此时使用<code>--force</code>可以强制推送，但是会覆盖远程</li><li>默认不推送标签，需要<code>--tags</code>的指令。</li></ul></li></ol><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>全局配置在<code>~/.gitconfig</code>中，可以在里面修改代理、<code>user</code>信息等</p><p><img src="//luyanfcp.github.io/2020/10/11/git笔记/7.png" srcset="/img/loading.gif" alt="git全局config"></p><p>可以使用指令<code>git config --global</code>进行设置</p><p>本地配置在<code>[project_dir]/.git/config</code>z中，其中配置更多的在本地的信息，比如说<code>分支信息</code>，<code>remote</code>信息等等</p><p><img src="//luyanfcp.github.io/2020/10/11/git笔记/8.png" srcset="/img/loading.gif" alt="git本地config"></p><h2 id="Git-理论"><a href="#Git-理论" class="headerlink" title="Git 理论"></a>Git 理论</h2><p>两个概念<code>Object Database</code>和<code>Current Directory cache</code></p><blockquote><p>暂时空下来，埋坑，之后补全</p></blockquote><h2 id="一些好用的小指令"><a href="#一些好用的小指令" class="headerlink" title="一些好用的小指令"></a>一些好用的小指令</h2><ol><li><code>git log --graph</code>可以用图的方式展示git当前分支的的<code>commit</code>情况。</li><li><p><code>git</code>设置代理：</p><ul><li><code>git config --global https.proxy [代理url]:[port]</code></li><li><code>git config --global http.proxy [代理url]:[port]</code></li><li>取消代理<code>git config --global --unset [https.proxy]/[http.proxy]</code>  </li></ul></li><li><p><code>git cherry-pick</code>： <a href="https://zhuanlan.zhihu.com/p/90816644" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/90816644</a></p></li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><p><a href="https://www.ruanyifeng.com/blog/2014/06/git_remote.html" target="_blank" rel="noopener">https://www.ruanyifeng.com/blog/2014/06/git_remote.html</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/71577255" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/71577255</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/132406345" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/132406345</a></p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>工具</tag>
      
      <tag>Git</tag>
      
      <tag>笔记搬运计划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《A Survey of Model Compression and Acceleration for Deep Neural Networks》笔记</title>
    <link href="/2019/09/15/ModelCompression/"/>
    <url>/2019/09/15/ModelCompression/</url>
    
    <content type="html"><![CDATA[<h2 id="Introduce"><a href="#Introduce" class="headerlink" title="Introduce"></a>Introduce</h2><p>随着DNN的层数和节点个数越来越多，它面临着两方面的问题。一方面它的计算和存储成本越来越高，对一些及时性的程序带来了挑战（在线学习和增量学习）；另一方面由于小型化设备越来越普及，小型设备对DNN越来越强。但由于体积和计算难度，DNN在小型设备上的部署也面临挑战。</p><p>本文综述了最近几年ML、最优化、计算机体系结构、数据压缩、硬件设计等等方面对DNN加速和压缩方面的进展。</p><p>本文讲这些进展分为四个部分：</p><ol><li>参数裁剪和共享（parameter pruning and sharing）。其方法主要是去除模型中的冗余和非临界参数。</li><li>低秩因子分解（low-rank factorization）。基于矩阵或者张量的分解，去估计DNN中参数的信息。</li><li>转移/紧凑卷积过滤器（transferred/compact convolutional filter）。它主要是设计特殊的卷积过滤结构去减少参数的空间，减少模型大小和计算量。</li><li>知识蒸馏（knowledge distilation）。知识蒸馏方法学习一个蒸馏模型，训练一个更紧凑的神经网络来重现一个更大的网络的输出。</li></ol><p><img src="//luyanfcp.github.io/2019/09/15/ModelCompression/1.png" srcset="/img/loading.gif" alt="总结"></p><p>这些方法都是独立的，我们可以将其混合使用而达到更高的压缩比和更快的速度。</p><h2 id="参数裁剪与共享"><a href="#参数裁剪与共享" class="headerlink" title="参数裁剪与共享"></a>参数裁剪与共享</h2><p>之前工作表明网络的裁剪是减少网络复杂度和解决过拟合问题的一种有效途径。之后的研究又发现它也是一种压缩网络的一种很有效的方式。这种方法有四个分支：量化（quantization）、二值化（binarization）、参数共享（parameter sharing）和结构化矩阵（structural matrix）。</p><h3 id="量化与二值化"><a href="#量化与二值化" class="headerlink" title="量化与二值化"></a>量化与二值化</h3><p>网络量化通过减少表示每个权值所需的比特数来压缩原始网络。Gong et al.和 Wu et al. 使用k-means对参数进行量化。 Vanhoucke et al 研究表明8-bit的量化参数可以在很小准确率损失的情况下显著的提升速度。Han Song提出一整套压缩模型的过程。首先将一个训练好的模型不断的剪枝然后重新训练。将剪过枝的矩阵进行稀疏化。最终得到一个稀疏的参数。再对其进行量化和权值共享进一步的去压缩参数，最终得到了很高的压缩比和很少准确率损失的模型。</p><p>Y. Choi et al.研究表明Hessian权值可以用来度量网络参数的重要性，并提出将聚类网络参数的平均Hessian weighted量化误差最小化。</p><p>另外当权值被表示成1bit时也就参数了二值量化网络。有许多工作直接将CNNs训练为二值量化网络，例如BinaryConnect， BinaryNet、XNORNet。他们的主要思想是在训练是直接学习二值化的权值和激活值(activation)。在研究中表明经过反向传播训练的网络对包括二进制权值在内的特定权值失真具有较强的恢复能力。</p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>在量化级较多的情况下准确率能够较好保持，但对于二值量化网络的准确率在处理大型CNN网络，如GoogleNet时会大大降低。二值化网络的另一个缺点是现有的二值化方案基于简单的矩阵逼近，忽略了二值化对精度损失的影响</p><p>为了解决这些问题，近期的工作又提出了一个使用对角Hessian 估计的近端牛顿法(proximal Newton algorithm)在二值化网络中最小损失。 ——-注意——</p><h3 id="剪枝与共享"><a href="#剪枝与共享" class="headerlink" title="剪枝与共享"></a>剪枝与共享</h3><p>剪枝与权值共享都可以减少网络的复杂度和解决过拟合问题。早期剪枝的方法是偏差权重衰减（Biased Weight Decay），其中最优脑损伤（Optimal Brain Damage）和最优脑手术（Optimal Brain Surgeon）方法，是基于损失函数的Hessian矩阵来减少连接的数量，实验表明这种剪枝的方法比通过权值绝对值阈值的剪值更有效。</p><p>最近的工作倾向是去裁剪预训练模型（pre-trained CNN model）冗余或者没有信息的权值。<br>主要进展为 Srinivas等人研究冗余情况，提出一个不需要数据的去除冗余神经元的方法（a data-free pruning method to remove redundant neurons）。Han等人提出了提出减少整个网络中参数和操作的总数的方法。Chen等人提出HashedNet实现了权值共享。Han Song提出了量化和权值共享综合的方法。 K. Ullrich等人提出了训练边剪枝和压缩的方法。</p><p>另一个发展方向就是训练具有稀疏约束（sparsity constraints）的紧凑的CNN。他们经常将l0或者l1范数调节器引入问题中。从而达到稀疏和剪枝的效果<br>这些稀疏约束通常作为l_0或l_1范数调节器在优化问题中引入。</p><p>V. Lebedev等人利用对卷积过滤器的稀疏约束来实现脑损伤。比如按组去修剪卷积核。</p><p><img src="//luyanfcp.github.io/2019/09/15/ModelCompression/2.png" srcset="/img/loading.gif" alt="pruning"></p><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><p>用l1或l2正则化进行剪枝需要比一般方法更多的迭代来收敛。此外，所有剪枝标准都需要手动设置层的灵敏度，这需要对参数进行微调，对于某些应用程序可能很麻烦。</p><h3 id="设计结构化的矩阵"><a href="#设计结构化的矩阵" class="headerlink" title="设计结构化的矩阵"></a>设计结构化的矩阵</h3><p>参数是矩阵是一个M<em>N的矩阵但是其描述参数比M</em>N少的多。他的优点是减少内存消耗，而且还可以通过快速的矩阵-向量乘法与梯度计算显著的加快推理和训练的速度。<br>当然它也有很多问题，比如说依赖先验知识，结构约束必定会导致精确度的损失，因此约束可能会给模型带来偏差。同样找到一个合适的结构矩阵非常困难，而且没有理论方法进行推导。因此无法广泛使用。</p><h2 id="低秩分解和稀疏性"><a href="#低秩分解和稀疏性" class="headerlink" title="低秩分解和稀疏性"></a>低秩分解和稀疏性</h2><p>卷积操作在CNN计算中占据了大量的计算量，因此减少卷积层将会提高压缩率和速度。对于卷积核，我们可以将它视为一个4D张量。因此对其进行分解会降低其中的冗余。FC层可以视为一个2D的矩阵，对其进行低秩分解可以减少冗余。</p><p>低秩估计是一层一层进行的。在一层完成之后一层的参数就被固定，后会通过重构误差准则再进行微调。如图<br><img src="//luyanfcp.github.io/2019/09/15/ModelCompression/3.png" srcset="/img/loading.gif" alt="low-rank"></p><p>沿着这个方向，又衍生了很大方法，比如说 CP 分解（Canonical Polyadic decomposition）和使用BN（Batch Normalization）去变换激活值。通常CP分解与BN都可以运用在从头训练CNNs。但是两者又有些不同。</p><p><img src="//luyanfcp.github.io/2019/09/15/ModelCompression/4.png" srcset="/img/loading.gif" alt="BN与CP"></p><h3 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h3><p>低秩方法是一种简单直接的模型压缩与加速的方法。这个想法在在深度学习方面最近有所补充，比如说Dropout、Rectified units 和 maxout。由于分解这个操作很难实现，而且分解操作的计算代价很大。另一个问题是，目前的方法是逐层执行低秩近似，因此不能执行全局参数压缩，这一点很重要，因为不同的层包含不同的信息。另外它还需要大量的模型重新训练来保证他的收敛性。</p><h2 id="转移-紧凑卷积过滤器"><a href="#转移-紧凑卷积过滤器" class="headerlink" title="转移/紧凑卷积过滤器"></a>转移/紧凑卷积过滤器</h2><hr><p>待续</p><hr><h2 id="知识蒸馏（knowledge-distillation）"><a href="#知识蒸馏（knowledge-distillation）" class="headerlink" title="知识蒸馏（knowledge distillation）"></a>知识蒸馏（knowledge distillation）</h2><p>Caruana等提出了知识迁移（knowledge transfer）去压缩模型。但是这种方法只存在与浅层学习中。其主要是训练一个对伪数据标签有强分类的一个压缩/集成模型。<br>该思想最近知识蒸馏（knowledge distillation）中被采用，并且可以使得深度模型转化为浅层模型。其主要思想是。通过softmax学习类的分布把大模型转化为小模型。</p><p>G. E. Hinton等人提出了KD压缩模型的框架，它通过student-teacher（学生会根据老师的软化<softed>的输出而被惩罚） 范式去进行DNN的训练。<br>A. Romero等人的工作通过使用一个瘦而深的网络去压缩一个宽而浅的网络。为了从teacher network中学到中间表示（intermediate representations），FitNet需要student network去模仿teacher network的所以特征，但是这个很难做到。<br>还有一些知识蒸馏的扩展方向：<br>A. Korattikara Balan等人的工作训练了一个参数化的学生模型来近似蒙特卡罗老师。该框架采用在线训练，学生模型采用深度神经网络。T. Chen等人使用较高隐层的神经元来表示知识，而不是使用软化标签概率（soften label probabilities）表示知识，它保留了与标签概率（ label probabilities）相同的信息，但更紧凑。T. Chen等人的工作使用及时训练的方式传递知识，加速网络的训练。S. Zagoruyko等人提出了 Attention Transfer（AT）的方法宽松了FitNet的假设。</softed></p><h3 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h3><p>KD-base 可以使得深度模型更轻量化，可以显著的减少计算花销。但是它只能用于softmax loss function做多分类的模型。还有就是它的模型假设太过于严格。</p><h2 id="基准、评估、数据库"><a href="#基准、评估、数据库" class="headerlink" title="基准、评估、数据库"></a>基准、评估、数据库</h2><p>作为基准的模型：<br><img src="//luyanfcp.github.io/2019/09/15/ModelCompression/5.png" srcset="/img/loading.gif" alt="常用的模型与压缩的方法"></p><h3 id="经典的评估方法"><a href="#经典的评估方法" class="headerlink" title="经典的评估方法"></a>经典的评估方法</h3><p>假设a是模型M的原始参数个数，a*是已经压缩过模型的参数个数。那么压缩率为</p><script type="math/tex; mode=display">\alpha(M, M^*) = \frac{a}{a^*}</script><p>也可以使用index space saving去度量</p><script type="math/tex; mode=display">\beta(M, M^*) = \frac{a - a^*}{a^*}</script><p>相同的加速比我们可以使用</p><script type="math/tex; mode=display">\delta(M, M^*) = \frac{s}{s^*}</script><p><strong>不同的CNN使用的压缩和加速方式不同，对于CNN来说，大部分参数集中在全连接层，而大部分运算量集中在前面的卷积层中</strong></p><h2 id="讨论与挑战"><a href="#讨论与挑战" class="headerlink" title="讨论与挑战"></a>讨论与挑战</h2><h3 id="一些建议"><a href="#一些建议" class="headerlink" title="一些建议"></a>一些建议</h3><p>没有绝对的对压缩与加速的方法，只能根据场景与需求选择相对较好的方法。</p><ul><li>如果是想要压缩预训练模型（pre-trained deep nets）的话可以使用剪枝、权值共享或者低秩分解。如果需要端到端（end-end）的解决方案的话使用低秩分解和转移卷积滤波器的方法</li><li>对于某些特定领域的应用，具有人类先验知识的支撑。使用一些转移卷积滤波器（transferred convolutional filter）和结构化矩阵（structural matrix）这些具有先验知识的方法效果会更好。</li><li>剪枝与共享的方法在不影响压缩精度的前提下，通常能给出合理的压缩率。因此，对于需要稳定模型性能的应用程序，最好使用剪枝和共享。</li><li>如果在时间场景中只包含 小型/中型的数据集可以尝试一下知识蒸馏的方法。这个方法在数据集不大的情况下有很高的鲁棒性。</li><li>上面的方法都是独立的，因此我们可以他们两三个组合。例如目标检测的这项领域，使用的模型往往都含有卷积层和全连接层。我们可以使用低秩分解等方法压缩CNN，可以使用剪枝等方法优化全连接层。</li></ul><h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><ul><li>大多数最新最好模型基本都是精心设计的，结构和参数能改动的空间很少。</li><li>各种小的硬件平台的约束，如何去充分利用有限的计算资源，如何为这些平台提供更好的压缩方式是一个很大挑战。</li><li>通道剪枝虽然可以有效的减少模型的尺寸，但是会极大的改变下一次的输入。</li><li>虽然各种压缩方法取得了巨大的成就，但是DNN的黑盒机制还是阻碍他应用的一个很关键问题。</li></ul><h3 id="可能的解决办法"><a href="#可能的解决办法" class="headerlink" title="可能的解决办法"></a>可能的解决办法</h3><p>为了解决超参数调参的问题，我们可以以来最近的learning-to-learn 策略。该框架运行算法可以自动优化结构和超参数，最近，利用强化学习来有效地采样设计空间和改进模型压缩也进行了尝试。</p><p>硬件感知（hardware-aware）也是加速CNN的一种途径。</p><p>通道剪枝（Clannel pruning）由于其对实现没有特殊需求，因此对GPU和CPU都有利。其有两种方法。一方面 使用基于训练的通道剪枝方法，其侧重对权重的稀疏化。但是这种方法需要从头开始训练因此花销很大。另一方面Liu等人研究表明，修剪后的体系结构更为关键。</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>模型压缩</tag>
      
      <tag>模型加速</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>WindowsTerminal尝鲜踩坑</title>
    <link href="/2019/09/15/wt/"/>
    <url>/2019/09/15/wt/</url>
    
    <content type="html"><![CDATA[<h1 id="WindowsTerminal尝鲜踩坑"><a href="#WindowsTerminal尝鲜踩坑" class="headerlink" title="WindowsTerminal尝鲜踩坑"></a>WindowsTerminal尝鲜踩坑</h1><h2 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h2><p>WindowsTerminal是微软新发布的一款Terminal产品（以下称），对比之前传统的<code>CMD</code>和<code>Powershell</code>来说，<code>WT</code>对定制的支持更好，同时又支持GPU对页面的渲染、emoj表情、多标签等的特点。<br>其项目地址为：<a href="https://github.com/microsoft/terminal" target="_blank" rel="noopener">https://github.com/microsoft/terminal</a></p><p>官方演示图片如下：<br><img src="//luyanfcp.github.io/2019/09/15/wt/1.png" srcset="/img/loading.gif" alt><br><img src="//luyanfcp.github.io/2019/09/15/wt/2.jpg" srcset="/img/loading.gif" alt></p><h2 id="如何获取"><a href="#如何获取" class="headerlink" title="如何获取"></a>如何获取</h2><p>现在<code>WT</code>仍然处于开发阶段，但是官方还是放出了一个preview的版本可以通过<code>Window Store</code>下载（ 链接：<a href="https://www.microsoft.com/en-us/p/windows-terminal-preview/9n0dx20hk701" target="_blank" rel="noopener">https://www.microsoft.com/en-us/p/windows-terminal-preview/9n0dx20hk701</a> ），也可以通过将<code>github</code>上的项目clone之后编译。</p><p><strong>但是无论是编译还是在官方下载的，都需要将window升级到1903</strong></p><h3 id="自己编译"><a href="#自己编译" class="headerlink" title="自己编译"></a>自己编译</h3><p>编译条件：</p><ul><li>在window中 设置-更新-开发者选项中中选择开发者模式</li><li>VS2017 或者 VS2019</li><li>Win10 SDK 10.018362（最新版SDK即可）</li><li>.net桌面开发</li><li>C++桌面开发</li><li>通用windows平台开发</li></ul><p>在进入VS的时候如果缺少哪一个，解决方案上方会有提示，直接按照上面的提示安装即可。</p><p>编译过程</p><ol><li>首先将项目使用<code>git clone https://github.com/microsoft/terminal.git</code>克隆本地</li><li>直接在该文件中双击<code>OpenConsole.sln</code>，在VS中打开</li><li>将调整为<img src="//luyanfcp.github.io/2019/09/15/wt/3.png" srcset="/img/loading.gif" alt>，在本地计算机中运行即可</li><li>如果想部署到电脑点击解决方案中的<code>Terminal/CascadiaPackage</code>右击生成、然后再右击部署即可。</li></ol><h2 id="如何定制一个属于自己的Terminal"><a href="#如何定制一个属于自己的Terminal" class="headerlink" title="如何定制一个属于自己的Terminal"></a>如何定制一个属于自己的Terminal</h2><p>新的<code>WT</code>最大的优点是相对与<code>Windows</code>之前的Terminal多了一些可定制性。设置主要分成四种</p><ol><li>快捷键的设置</li><li>shell</li><li>页面</li><li>配色</li></ol><h3 id="profiles-json文件"><a href="#profiles-json文件" class="headerlink" title="profiles.json文件"></a>profiles.json文件</h3><p>Terminal的设置是一个json文件，名字为<code>profiles.json</code>中。此文件可以通过<code>WT</code>的下拉菜单的<code>setting</code>中。此文件位于<code>%USERDIR\AppData\Local\Packages\Microsoft.WindowsTerminal_8wekyb3d8bbwe\RoamingState</code>中（preview）或者<code>%USERDIR\AppData\Local\Packages\WindowsTerminalDev_8wekyb3d8bbwe\RoamingState\profiles.json</code>中（自己编译和部署的），其中<code>%USERDIR</code>为用户目录。</p><blockquote><p>踩坑指南:</p><p>如果profiles.json中有配置错误的地方Terminal就会无法打开，这个BUG现在修复中。因此如果无法打开Terminal的话，首先要检查profiles.json中是否有配置错误的地方，尤其小心字母打错。</p><p>还有就是如果preview版本的配置会同步到Windows账户，如果在其他的电脑上下载的WT的preview版本，但是无法打开时，就要检查profiles.json中的字体和图片是否是正确的或者是否存在这个字体和图片。<br>还有就是使用WinAPP的清除配置的方式清除配置无法清除profiles.json</p></blockquote><h4 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h4><p>此处采用key-value模式进行设置，在json中设置如下：<br>其中command有如下的种类：</p><pre><code class="hljs c#">enum class ShortcutAction : int32_t    &#123;        CopyText = 0,        PasteText = 1,        NewTab = 2,        NewTabProfile0 = 3,        NewTabProfile1 = 4,        NewTabProfile2 = 5,        NewTabProfile3 = 6,        NewTabProfile4 = 7,        NewTabProfile5 = 8,        NewTabProfile6 = 9,        NewTabProfile7 = 10,        NewTabProfile8 = 11,        NewWindow = 12,        CloseWindow = 13,        CloseTab = 14,        NextTab = 15,        PrevTab = 16,        SplitVertical = 17,        SplitHorizontal = 18,        SwitchToTab0 = 19,        SwitchToTab1 = 20,        SwitchToTab2 = 21,        SwitchToTab3 = 22,        SwitchToTab4 = 23,        SwitchToTab5 = 24,        SwitchToTab6 = 25,        SwitchToTab7 = 26,        SwitchToTab8 = 27,        IncreaseFontSize = 28,        DecreaseFontSize = 29,        ScrollUp = 30,        ScrollDown = 31,        ScrollUpPage = 32,        ScrollDownPage = 33,        OpenSettings = 34,    &#125;;</code></pre><p>在<code>profiles.json</code>中的配置</p><pre><code class="hljs json">"keybindings" :        [            &#123;                "command" : "closeTab", // 这里是命令                "keys" :  // 这是快捷键                [                    "ctrl+w"                ]            &#125;        ]</code></pre><h3 id="页面的配置"><a href="#页面的配置" class="headerlink" title="页面的配置"></a>页面的配置</h3><p>页面配置主要分为全局页面配置和每一个profile的页面配置</p><h4 id="全局页面配置"><a href="#全局页面配置" class="headerlink" title="全局页面配置"></a>全局页面配置</h4><p>全局页面设置常用的主要为: </p><ul><li>设置窗口大小，使用 <code>initialCols</code> 和 <code>initialRows</code></li><li>默认打开的Shell，通过使用<code>defaultProfile</code>，它的参数为一个string类型的guid，每一个profile都有自己的guid，格式为<code>&quot;{00000000-0000-0000-0000-000000000000}&quot;</code><br>例如在我的配置中<pre><code class="hljs json">&#123;    <span class="hljs-attr">"globals"</span>: &#123;        <span class="hljs-attr">"defaultProfile"</span> :<span class="hljs-string">"&#123;61c54bbd-c2c6-5271-96e7-009a87ff44bf&#125;"</span>,    &#125;,    <span class="hljs-attr">"profiles"</span>: [        &#123;            <span class="hljs-attr">"commandline"</span> : <span class="hljs-string">"powershell.exe"</span>,            <span class="hljs-attr">"guid"</span> : <span class="hljs-string">"&#123;61c54bbd-c2c6-5271-96e7-009a87ff44bf&#125;"</span>        &#125;    ]&#125;</code></pre></li></ul><p>这样无论是直接打开<code>WT</code>还是按<code>+</code>按钮打开一个新的tab都默认是的<code>powershell</code></p><h4 id="页面配置"><a href="#页面配置" class="headerlink" title="页面配置"></a>页面配置</h4><pre><code class="hljs json">&#123;    "acrylicOpacity" : 0.5, // 透明度    "closeOnExit" : true,    "colorScheme" : "Campbell", //主题    "commandline" : "wsl.exe -d Ubuntu-18.04", // 启动shell的命令    "cursorColor" : "#FFFFFF", // 光标的颜色    "cursorShape" : "bar", //光标的形状，变量有 "vintage" ( ▃ ), "bar" ( ┃ ), "underscore" ( ▁ ), "filledBox" ( █ ), "emptyBox" ( ▯ )    "fontFace" : "Fira Code", // 字体设置    "background" : "#000000", // 背景颜色， 它会覆盖掉主题中的background     "fontSize" : 15, // 字体大小    "guid" : "&#123;c6eaf9f4-32a7-5fdc-b5cf-066e8a4b1e40&#125;", // guid 必须为"&#123;00000000-0000-0000-0000-000000000000&#125;"格式    "historySize" : 9001, // 能显示的历史命令个数    "icon" : "ms-appx:///ProfileIcons/&#123;9acb9455-ca41-5af7-950f-6bca1bc9722f&#125;.png",     "name" : "Ubuntu-18.04", // 名称，显示在菜单中    "padding" : "0, 0, 0, 0",    "snapOnInput" : true,    "useAcrylic" : false, // 是否显示背后的纹理    "backgroundImage" : "ms-appdata:///roaming/test.jpg", // 图片的一个路径,需要绝对路径    "backgroundImageOpacity" : 0.75,  // 背景图的透明度    "backgroundImageStrechMode" : "fill" // 填充方式&#125;</code></pre><p>这里要特别注意三个设置</p><ol><li><code>background</code> 如果在<code>profile</code>中设置的话会覆盖<code>theme</code>中的<code>background</code>。</li><li><code>acrylicOpacity</code>这个属性生效的前提是<code>useAcrylic</code>的值为<code>true</code></li><li><code>backgroundImage</code> 等属性生效的前提是<code>useAcrylic</code>的值为<code>false</code></li></ol><p><strong><code>useAcrylic</code> 这个属性是决定能不能通过页面去显示页面后的内容</strong><br>例如：<br>当<code>&quot;useAcrylic&quot; : true</code>时，效果如下</p><p><img src="//luyanfcp.github.io/2019/09/15/wt/4.png" srcset="/img/loading.gif" alt><br>此时可以通过<code>acrylicOpacity</code>去调节透明度。此时背景图片的设置就无法实现。如果要设置背景图片的话使用<code>&quot;useAcrylic&quot; : false</code>再进行设置</p><h3 id="主题配置"><a href="#主题配置" class="headerlink" title="主题配置"></a>主题配置</h3><p>主题的配置在<code>profiles.json</code>文件中的<code>schemes</code>属性中,官方为我们提供了<code>Campbell、One Half Dark、One Half Light、Solarized Dark、Solarized Light</code>五种默认的主题。我们可以在profiles中直接设置使用。</p><p>我们也可以自建主题，相关的配置参数如下：</p><p><img src="//luyanfcp.github.io/2019/09/15/wt/5.png" srcset="/img/loading.gif" alt></p><p>同时官方又给我们提供<code>ColorTool</code>工具帮助我们更快的设置主题颜色，<code>ColorTool</code>可以直接使用<code>iterm2</code>的配色文件，因此能够让我们更多样的选择主题。</p><p>但博主无法使用改工具对<code>WT</code>的配色进行修改，找了<code>issue</code>和各种资料均为找到答案。可能是<code>ColorTool</code>尚未实现对<code>WT</code>的操作，只实现了对<code>CMD</code>、<code>PowerShell</code>、<code>WSL</code>的操作。</p>]]></content>
    
    
    
    <tags>
      
      <tag>terminal</tag>
      
      <tag>win</tag>
      
      <tag>工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
